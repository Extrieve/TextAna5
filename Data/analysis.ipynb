{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string, re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('../Data/BBC-articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sport</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sport</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>last star wars  not for children  the sixth an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "5       politics  howard hits back at mongrel jibe michael howar...\n",
       "6       politics  blair prepares to name poll date tony blair is...\n",
       "7          sport  henman hopes ended in dubai third seed tim hen...\n",
       "8          sport  wilkinson fit to face edinburgh england captai...\n",
       "9  entertainment  last star wars  not for children  the sixth an..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can do this using LSI/LSA and LDA algorithms, after vectorizing the text using TF-IDF vector in three different ways:\n",
    "\n",
    "- TF-IDF after normal cleaning of the text corpus (punctuation removal, stopword removal, etc.)\n",
    "- TF-IDF with term frequency filter, to exclude the top 10% of the most frequent words and words that appear less than 5 times in the documents.\n",
    "- TF-IDF limited to nouns, noun phrases, and named entity recognition only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nick/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nick/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "## lets use nltk to extract the most significant words from each article to also use TF-IDF and LSI and LDA\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# stopwords from gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF after normal cleaning of the text corpus (punctuation removal, stopword removal, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_clean(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove whitespace\n",
    "    text = text.strip()\n",
    "    # remove stopwords with gensim\n",
    "    text = [word for word in text.split() if word not in STOPWORDS]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>[tv, future, hands, viewers, home, theatre, sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>[worldcom, boss, left, books, worldcom, boss, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>[tigers, wary, farrell, gamble, leicester, rus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>[ocean, s, raids, box, office, ocean, s, crime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "      <td>[howard, hits, mongrel, jibe, michael, howard,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "      <td>[blair, prepares, poll, date, tony, blair, lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sport</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "      <td>[henman, hopes, ended, dubai, seed, tim, henma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sport</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "      <td>[wilkinson, fit, face, edinburgh, england, cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>last star wars  not for children  the sixth an...</td>\n",
       "      <td>[star, wars, children, sixth, final, star, war...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "5       politics  howard hits back at mongrel jibe michael howar...   \n",
       "6       politics  blair prepares to name poll date tony blair is...   \n",
       "7          sport  henman hopes ended in dubai third seed tim hen...   \n",
       "8          sport  wilkinson fit to face edinburgh england captai...   \n",
       "9  entertainment  last star wars  not for children  the sixth an...   \n",
       "\n",
       "                                         clean_text1  \n",
       "0  [tv, future, hands, viewers, home, theatre, sy...  \n",
       "1  [worldcom, boss, left, books, worldcom, boss, ...  \n",
       "2  [tigers, wary, farrell, gamble, leicester, rus...  \n",
       "3  [yeading, face, newcastle, fa, cup, premiershi...  \n",
       "4  [ocean, s, raids, box, office, ocean, s, crime...  \n",
       "5  [howard, hits, mongrel, jibe, michael, howard,...  \n",
       "6  [blair, prepares, poll, date, tony, blair, lik...  \n",
       "7  [henman, hopes, ended, dubai, seed, tim, henma...  \n",
       "8  [wilkinson, fit, face, edinburgh, england, cap...  \n",
       "9  [star, wars, children, sixth, final, star, war...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the text\n",
    "df['clean_text1'] = df['text'].apply(normal_clean)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF after normal cleaning of the text corpus (punctuation removal, stopword removal, etc.)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vectorizer object\n",
    "vectorizer_1 = TfidfVectorizer(stop_words='english', max_features= 2000, max_df = 0.5, smooth_idf=True)\n",
    "\n",
    "# fit and transform the vectorizer on the text\n",
    "X = vectorizer_1.fit_transform(df['clean_text1'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text1</th>\n",
       "      <th>tfidf_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>[tv, future, hands, viewers, home, theatre, sy...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>[worldcom, boss, left, books, worldcom, boss, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>[tigers, wary, farrell, gamble, leicester, rus...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>[ocean, s, raids, box, office, ocean, s, crime...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "      <td>[howard, hits, mongrel, jibe, michael, howard,...</td>\n",
       "      <td>[0.0, 0.032974084459105844, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "      <td>[blair, prepares, poll, date, tony, blair, lik...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sport</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "      <td>[henman, hopes, ended, dubai, seed, tim, henma...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sport</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "      <td>[wilkinson, fit, face, edinburgh, england, cap...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>last star wars  not for children  the sixth an...</td>\n",
       "      <td>[star, wars, children, sixth, final, star, war...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "5       politics  howard hits back at mongrel jibe michael howar...   \n",
       "6       politics  blair prepares to name poll date tony blair is...   \n",
       "7          sport  henman hopes ended in dubai third seed tim hen...   \n",
       "8          sport  wilkinson fit to face edinburgh england captai...   \n",
       "9  entertainment  last star wars  not for children  the sixth an...   \n",
       "\n",
       "                                         clean_text1  \\\n",
       "0  [tv, future, hands, viewers, home, theatre, sy...   \n",
       "1  [worldcom, boss, left, books, worldcom, boss, ...   \n",
       "2  [tigers, wary, farrell, gamble, leicester, rus...   \n",
       "3  [yeading, face, newcastle, fa, cup, premiershi...   \n",
       "4  [ocean, s, raids, box, office, ocean, s, crime...   \n",
       "5  [howard, hits, mongrel, jibe, michael, howard,...   \n",
       "6  [blair, prepares, poll, date, tony, blair, lik...   \n",
       "7  [henman, hopes, ended, dubai, seed, tim, henma...   \n",
       "8  [wilkinson, fit, face, edinburgh, england, cap...   \n",
       "9  [star, wars, children, sixth, final, star, war...   \n",
       "\n",
       "                                             tfidf_1  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061...  \n",
       "5  [0.0, 0.032974084459105844, 0.0, 0.0, 0.0, 0.0...  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add vectorizer to dataframe\n",
    "df['tfidf_1'] = [x for x in X.toarray()]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with term frequency filter, to exclude the top 10% of the most frequent words and words that appear less than 5 times in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 52567),\n",
       " ('to', 24955),\n",
       " ('of', 19947),\n",
       " ('and', 18561),\n",
       " ('a', 18251),\n",
       " ('in', 17570),\n",
       " ('s', 9007),\n",
       " ('for', 8884),\n",
       " ('is', 8515),\n",
       " ('that', 8135)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF with term frequency filtering, we will exluding the top 10% of terms with the highest term frequency for the entire corpus\n",
    "\n",
    "word_frequencies = dict()\n",
    "\n",
    "for text in df['text']:\n",
    "    for word in text.split():\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "\n",
    "\n",
    "sorted(list(word_frequencies.items()), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_percent = int(len(word_frequencies) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profits.', 19),\n",
       " ('recovered', 19),\n",
       " ('strategist', 19),\n",
       " ('consortium', 19),\n",
       " ('avoided', 19),\n",
       " ('motor', 19),\n",
       " ('bank.', 19),\n",
       " ('hopeful', 19),\n",
       " ('christmas.', 19),\n",
       " ('attachment', 19)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the top_10_percent words from the word_frequencies dictionary\n",
    "for word in sorted(word_frequencies, key=word_frequencies.get, reverse=True)[:top_10_percent]:\n",
    "    del word_frequencies[word]\n",
    "\n",
    "sorted(list(word_frequencies.items()), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39394"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8022"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any item in word_frequencies that appears less than 5 times\n",
    "for word in list(word_frequencies):\n",
    "    if word_frequencies[word] < 5:\n",
    "        del word_frequencies[word]\n",
    "\n",
    "len(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets tokenize the text and only add words that are in the word_frequencies dictionary\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token in word_frequencies]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new clean_text2 column using the tokenize_text function\n",
    "df['clean_text2'] = df['text'].apply(lambda x: tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text1</th>\n",
       "      <th>tfidf_1</th>\n",
       "      <th>clean_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>[tv, future, hands, viewers, home, theatre, sy...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030...</td>\n",
       "      <td>[plasma, tvs, radically, rooms, set-top, tivo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>[worldcom, boss, left, books, worldcom, boss, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[bernie, overseeing, $11bn, witness, myers, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>[tigers, wary, farrell, gamble, leicester, rus...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[tigers, wary, gamble, rushed, tigers, wells, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[arguably, slough, exeter, trafford, holders, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>[ocean, s, raids, box, office, ocean, s, crime...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061...</td>\n",
       "      <td>[twelve, raids, twelve, clooney, brad, pitt, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "      <td>[howard, hits, mongrel, jibe, michael, howard,...</td>\n",
       "      <td>[0.0, 0.032974084459105844, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[mongrel, jibe, hain, mongrel, rattled, opposi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "      <td>[blair, prepares, poll, date, tony, blair, lik...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[prepares, marr, resisted, recently., frantic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sport</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "      <td>[henman, hopes, ended, dubai, seed, tim, henma...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[quarter-final, ivan, croatian, halted, rain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sport</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "      <td>[wilkinson, fit, face, edinburgh, england, cap...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[long-awaited, 25-year-old, murrayfield, bench...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>last star wars  not for children  the sixth an...</td>\n",
       "      <td>[star, wars, children, sixth, final, star, war...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[suitable, film-maker, lucas, revenge, violent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "5       politics  howard hits back at mongrel jibe michael howar...   \n",
       "6       politics  blair prepares to name poll date tony blair is...   \n",
       "7          sport  henman hopes ended in dubai third seed tim hen...   \n",
       "8          sport  wilkinson fit to face edinburgh england captai...   \n",
       "9  entertainment  last star wars  not for children  the sixth an...   \n",
       "\n",
       "                                         clean_text1  \\\n",
       "0  [tv, future, hands, viewers, home, theatre, sy...   \n",
       "1  [worldcom, boss, left, books, worldcom, boss, ...   \n",
       "2  [tigers, wary, farrell, gamble, leicester, rus...   \n",
       "3  [yeading, face, newcastle, fa, cup, premiershi...   \n",
       "4  [ocean, s, raids, box, office, ocean, s, crime...   \n",
       "5  [howard, hits, mongrel, jibe, michael, howard,...   \n",
       "6  [blair, prepares, poll, date, tony, blair, lik...   \n",
       "7  [henman, hopes, ended, dubai, seed, tim, henma...   \n",
       "8  [wilkinson, fit, face, edinburgh, england, cap...   \n",
       "9  [star, wars, children, sixth, final, star, war...   \n",
       "\n",
       "                                             tfidf_1  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061...   \n",
       "5  [0.0, 0.032974084459105844, 0.0, 0.0, 0.0, 0.0...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         clean_text2  \n",
       "0  [plasma, tvs, radically, rooms, set-top, tivo,...  \n",
       "1  [bernie, overseeing, $11bn, witness, myers, co...  \n",
       "2  [tigers, wary, gamble, rushed, tigers, wells, ...  \n",
       "3  [arguably, slough, exeter, trafford, holders, ...  \n",
       "4  [twelve, raids, twelve, clooney, brad, pitt, j...  \n",
       "5  [mongrel, jibe, hain, mongrel, rattled, opposi...  \n",
       "6  [prepares, marr, resisted, recently., frantic,...  \n",
       "7  [quarter-final, ivan, croatian, halted, rain, ...  \n",
       "8  [long-awaited, 25-year-old, murrayfield, bench...  \n",
       "9  [suitable, film-maker, lucas, revenge, violent...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
